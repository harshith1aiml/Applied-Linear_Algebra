{"cells":[{"cell_type":"markdown","metadata":{"id":"M7g7bxFCHxGP"},"source":["$${\\color{yellow}{\\text{Applied Linear Algebra: Vectors and Matrices}}}$$\n","\n"]},{"cell_type":"markdown","source":["---\n","\n","Restart the session after executing the following cell\n","\n","---"],"metadata":{"id":"H6RvcDldxHPO"}},{"cell_type":"code","source":["!pip install gensim"],"metadata":{"id":"LapV0XR-wxSI","colab":{"base_uri":"https://localhost:8080/","height":805},"executionInfo":{"status":"ok","timestamp":1754402243447,"user_tz":-330,"elapsed":26002,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"78295e3a-46c0-42c3-b283-20d9b1b3c2f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gensim\n","  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n","Collecting numpy<2.0,>=1.18.5 (from gensim)\n","  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n","  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0.post1)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n","Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.16.0\n","    Uninstalling scipy-1.16.0:\n","      Successfully uninstalled scipy-1.16.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy","scipy"]},"id":"0bbdc47081e24650a34f831abeb67179"}},"metadata":{}}]},{"cell_type":"markdown","source":["---\n","\n","Load essential libraries\n","\n","---"],"metadata":{"id":"jDK9fC6uiBGE"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"20W0d4ruQjE4"},"outputs":[],"source":["import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","plt.style.use('dark_background')\n","%matplotlib inline\n","import sys\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n","import nltk\n","import gensim.downloader\n","from nltk.tokenize import word_tokenize"]},{"cell_type":"markdown","metadata":{"id":"sfYXkqmLiVLM"},"source":["---\n","\n","Mount Google Drive folder if running Google Colab\n","\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VYzBBBxqiaGa"},"outputs":[],"source":["## Mount Google drive folder if running in Colab\n","if('google.colab' in sys.modules):\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount = True)\n","    DIR = '/content/drive/MyDrive/Colab Notebooks/MAHE/MSIS Coursework/OddSem2025MAHE\n","    DATA_DIR = DIR+'/Data/'\n","else:\n","    DATA_DIR = 'Data/'"]},{"cell_type":"markdown","metadata":{"id":"avVZ6D1ZgEUT"},"source":["---\n","\n","**We will now use Pytorch to create tensors**\n","\n","The patient data matrix:\n","\n","![patient data matrix](https://1drv.ms/i/s!AjTcbXuSD3I3hsxIkL4V93-CGq8RkQ?embed=1&width=1000)\n","\n","**Notation**:\n","\n","Zeroth patient vector $\\mathbf{x}^{(0)}= \\begin{bmatrix}72\\\\120\\\\37.3\\\\104\\\\32.5\\end{bmatrix}$ and zeroth feature (heart rate vector) $\\mathbf{x}_0 = \\begin{bmatrix}72\\\\85\\\\68\\\\90\\\\84\\\\78\\end{bmatrix}.$\n","\n","---\n","\n"]},{"cell_type":"markdown","source":["Understanding pen & paper versions of tensors wrt to their representation in code"],"metadata":{"id":"Q_7AIxOs1KQF"}},{"cell_type":"code","source":["# pen and paper : 3-vecto, Code : rank-1 trensor\n","\n","a_vector = torch.tensor([1.0,2.0,3.0],dtype=torch.float64)\n","print(a_vector)\n","print(a_vector.shape)\n","print(type(a_vector))\n","\n","print(\"----------------\")\n","\n","# pen and paper : 1 X 3-matrix, Code : rank-2 trensor\n","\n","a_matrix_v1 = torch.tensor([[1.0,2.0,3.0]] , dtype=torch.float64)\n","print(a_matrix_v1)\n","print(a_matrix_v1.shape)\n","print(type(a_vector))\n","\n","print(\"----------------\")\n","\n","# pen and paper : 3 X 1-matrix, Code : rank-2 trensor\n","\n","a_matrix_v2 = torch.tensor([[1.0],[2.0],[3.0]] , dtype=torch.float64)\n","print(a_matrix_v2)\n","print(a_matrix_v2.shape)\n","print(type(a_vector))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E5siTIPq1Wv8","executionInfo":{"status":"ok","timestamp":1754005180164,"user_tz":-330,"elapsed":14,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"d54fc1de-2a82-43c2-f244-b1fb443c6125"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., 2., 3.], dtype=torch.float64)\n","torch.Size([3])\n","<class 'torch.Tensor'>\n","----------------\n","tensor([[1., 2., 3.]], dtype=torch.float64)\n","torch.Size([1, 3])\n","<class 'torch.Tensor'>\n","----------------\n","tensor([[1.],\n","        [2.],\n","        [3.]], dtype=torch.float64)\n","torch.Size([3, 1])\n","<class 'torch.Tensor'>\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zrPnepAEvr0O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753854470956,"user_tz":-330,"elapsed":167,"user":{"displayName":"S N S Acharya","userId":"14786945180387920086"}},"outputId":"e8211816-bfbb-43bd-cc2c-1cff75f3e340"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 72.0000, 120.0000,  37.3000, 104.0000,  32.5000],\n","        [ 85.0000, 130.0000,  37.0000, 110.0000,  14.0000],\n","        [ 68.0000, 110.0000,  38.5000, 125.0000,  34.0000],\n","        [ 90.0000, 140.0000,  38.0000, 130.0000,  26.0000],\n","        [ 84.0000, 132.0000,  38.3000, 146.0000,  30.0000],\n","        [ 78.0000, 128.0000,  37.2000, 102.0000,  12.0000]])\n","torch.Size([6, 5])\n","<class 'torch.Tensor'>\n","tensor([ 72.0000, 120.0000,  37.3000, 104.0000,  32.5000])\n","tensor([ 72.0000, 120.0000,  37.3000, 104.0000,  32.5000])\n","------------\n","tensor(37.3000)\n","tensor([37.3000, 37.0000, 38.5000, 38.0000, 38.3000, 37.2000])\n"]}],"source":["## Create a patient data matrix as a constant tensor\n","X = torch.tensor([[72, 120, 37.3, 104, 32.5],\n","                  [85, 130, 37.0, 110, 14],\n","                  [68, 110, 38.5, 125, 34],\n","                  [90, 140, 38.0, 130, 26],\n","                  [84, 132, 38.3, 146, 30],\n","                  [78, 128, 37.2, 102, 12]])\n","print(X)\n","print(X.shape)\n","print(type(X))\n","print(X[0]) # this is patient-0 information which is a rank-1 tensor\n","print(X[0, :]) # patient-0 all features\n","print('------------')\n","print(X[0, 2]) # feature-2 of patient-0, temperature of patient-0\n","print(X[:, 2]) # feature-2 of all patients, temperature of all patients"]},{"cell_type":"markdown","metadata":{"id":"cevtn_b4gek5"},"source":["---\n","\n","**Convert a PyTorch object into a numpy array**\n","\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JrYQ2moygfPu"},"outputs":[],"source":["print(X.numpy())\n","print(type(X.numpy()))"]},{"cell_type":"markdown","metadata":{"id":"QS3MmzwsgkWU"},"source":["---\n","\n","**Addition and subtraction of vectors, scalar multiplication (apply operation componentwise)**\n","\n","![vector addition](https://1drv.ms/i/c/37720f927b6ddc34/IQQ03G17kg9yIIA3NokBAAAAAZLAaAoWwhtn8Vk26NotALo?width=256)\n","\n","![vector subtracton](https://1drv.ms/i/c/37720f927b6ddc34/IQQ03G17kg9yIIA3M4kBAAAAAU_n_mAEv006QFZm_sUj2Dc?width=256)\n","\n","![vector multiplication](https://1drv.ms/i/c/37720f927b6ddc34/IQQ03G17kg9yIIA3NIkBAAAAAa_qL04bLT4kWoNeHcrR9LQ?width=256)\n","\n","![vector geometry1](https://1drv.ms/i/c/37720f927b6ddc34/IQSGNMr5z3SSRry7LSKL7LybAcGYuzgw5smabV8-6DudXIs?width=230)\n","\n","![vector geometry2](https://1drv.ms/i/c/37720f927b6ddc34/IQQ03G17kg9yIIA3WokBAAAAAQi8FPV9YCebl5WnyEKJ3vg?width=213&height=192)\n","\n","\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TgPtJP0sglQP"},"outputs":[],"source":["# Vector addition\n","print(X[1, :] + X[2, :])\n","\n","# Vector subtraction\n","print(X[1, :] - X[2, :])\n","\n","# Scalar-vector multiplication\n","print(X[:, 2])\n","print((9/5)*X[:, 2]+32) # 0peration not defined in pen & paper but in computation is referred to as\n","# broadcasting\n","\n","# Average patient\n","x_avg = (1/6)*(X[0, :] + X[1, :] + X[2, :] + X[3, :] + X[4, :] + X[5, :])\n","x_avg = torch.mean(X, dim = 0) # dim = 0 means top-to-bottom or along dim-0\n","\n","# Another broadcasting example\n","print(X)\n","print(x_avg)\n","print(X - x_avg)"]},{"cell_type":"markdown","metadata":{"id":"1t_qXrlCROKA"},"source":["---\n","\n","Application of vector subtraction in natural language processing (NLP): download the word embedding model trained on Wikipedia articles.\n","\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_e13FnW0RUwy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754003337513,"user_tz":-330,"elapsed":33522,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"dd731ba9-3d0b-4876-f70f-f99600c342e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["[==================================================] 100.0% 66.0/66.0MB downloaded\n"]}],"source":["model = gensim.downloader.load('glove-wiki-gigaword-50')"]},{"cell_type":"markdown","metadata":{"id":"7YRVJferRlK5"},"source":["---\n","\n","Now we will see what embedding vector comes as a result of applying the model for the words *cricket* and *football*.\n","\n","Next, we will do an *intuitive* subtraction of word embeddings as in\n","\n","1. Cricket without Tendulkar\n","2. Football without Messi\n","\n","Note that the embedding vectors have 50 components corresponding to the 50-dimensional embedding of model suggested by the name '**glove-wiki-gigaword-50**'\n","\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HVVFzeQyR3Wb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753854275446,"user_tz":-330,"elapsed":55,"user":{"displayName":"S N S Acharya","userId":"14786945180387920086"}},"outputId":"29825ac2-afcf-4718-b0dd-95c0708f8a95"},"outputs":[{"output_type":"stream","name":"stdout","text":["[-0.7716      0.41267997 -1.725968   -0.10445005 -1.1475699  -0.854661\n"," -1.089      -0.08342999  0.62349    -1.67822    -0.2488078  -0.49199998\n","  0.18756002 -1.67098     0.6117872   0.42784432  1.05656     0.91583097\n"," -0.03299999 -0.04422501  0.200326   -0.33737004  0.31068     1.37842\n"," -1.13689    -0.57445    -0.70685995  0.41552    -0.28937     0.54485\n","  1.0492998   0.62732    -0.8105     -1.27723    -0.02612001  0.53963\n"," -0.14065999 -0.738244   -0.30487    -1.18129     0.05651999 -0.993618\n"," -0.911399   -0.09289992  0.535432    0.26259995 -0.63031     0.64473\n","  0.77843     0.15099996]\n","[-2.06898     0.66804904 -1.077512    0.79964995 -0.27109998 -0.26289004\n"," -0.881       0.377503   -0.10869002 -2.47329    -0.23453003 -0.58438\n","  0.10404003 -0.52671003 -0.03030002  0.237764    0.19168997  1.60344\n"," -0.42980003  0.59058     0.59800005 -0.67075     0.45888     1.4538\n"," -1.15642    -1.63534    -1.1248189  -0.20879    -0.00812     0.25545004\n","  1.92044     0.30049008  0.19949001 -0.675167   -0.15230002  0.13278002\n"," -0.29492003 -0.55414    -0.30988902 -0.34549004 -0.72603    -1.20504\n"," -0.45038998  0.51834     0.12448996  0.787596   -1.13398     0.91365004\n"," -0.280479    0.76741004]\n","[ 1.29738    -0.25536907 -0.648456   -0.9041     -0.8764699  -0.59177095\n"," -0.208      -0.460933    0.73218     0.79506993 -0.01427777  0.09237999\n","  0.08352    -1.14427     0.6420872   0.19008031  0.8648701  -0.6876091\n","  0.39680004 -0.63480496 -0.39767405  0.33337998 -0.1482     -0.07537997\n","  0.01952994  1.06089     0.41795897  0.62431    -0.28125     0.28939995\n"," -0.8711401   0.3268299  -1.00999    -0.602063    0.12618001  0.40684998\n","  0.15426004 -0.18410403  0.00501901 -0.8358      0.78255     0.21142197\n"," -0.46100903 -0.6112399   0.41094202 -0.52499604  0.50367004 -0.26892006\n","  1.0589089  -0.6164101 ]\n"]}],"source":["# Cricket without Tendulkar\n","a = model['cricket'] - model['tendulkar']\n","\n","# Football without Messi\n","b = model['football'] - model['messi']\n","print(a)\n","print(b)\n","\n","# How different is cricket-without-tendulkar from\n","# football-without-messi?\n","print(a-b)"]},{"cell_type":"markdown","metadata":{"id":"8VPICS8ggvvg"},"source":["---\n","\n","A tensor of rank 3 corresponding to 4 time stamps (hourly), 3 samples (patients), 2 features (HR and BP). Assume that admission time is 9AM.\n","\n","---"]},{"cell_type":"code","source":["# A rank-3 patient tensor with shape (4, 3, 2)\n","# with meaning for\n","# dim-0 as 4 hourly timestamps,\n","# dim-1 as 3 patients, and\n","# dim-2 as 2 features (HR and BP)\n","# T = torch.tensor([[[HR, BP], [HR, BP], [HR, BP]],\n","#                   [[HR, BP], [HR, BP], [HR, BP]],\n","#                   [[HR, BP], [HR, BP], [HR, BP]],\n","#                   [[HR, BP], [HR, BP], [HR, BP]]])\n","T = torch.tensor([[[74., 128], [79, 116], [71, 116]],\n","                 [[78, 118], [82, 124], [72, 128]],\n","                 [[84, 138], [84, 130], [74, 120]],\n","                 [[82, 126], [76, 156], [82, 132]]])\n","print(T)"],"metadata":{"id":"yQAvgkRkWAM8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753937270779,"user_tz":-330,"elapsed":136,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"7d9b0965-45af-469b-81b1-cf471d074908"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[ 74., 128.],\n","         [ 79., 116.],\n","         [ 71., 116.]],\n","\n","        [[ 78., 118.],\n","         [ 82., 124.],\n","         [ 72., 128.]],\n","\n","        [[ 84., 138.],\n","         [ 84., 130.],\n","         [ 74., 120.]],\n","\n","        [[ 82., 126.],\n","         [ 76., 156.],\n","         [ 82., 132.]]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"JV0fpSojg2EZ"},"source":["---\n","\n","**Accessing elements of a tensor**\n","\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1GbZuDYqg22n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753937462801,"user_tz":-330,"elapsed":11,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"a710969e-1187-4e02-9007-500c5f275491"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(132.)\n","tensor([[ 74., 128.],\n","        [ 79., 116.],\n","        [ 71., 116.]])\n","tensor([[ 82., 126.],\n","        [ 76., 156.],\n","        [ 82., 132.]])\n","tensor([ 82., 132.])\n"]}],"source":["## Accessing elements of a tensor\n","# Rank-3 tensor T has axes order (timestamps, patients, features)\n","\n","# Element of T at postion 3 w.r.t. dim-0, position 2 w.r.t. dim-1,\n","# position-1 w.r.t dim-2\n","print(T[3, 2, 1]) # BP of patient-2 at noon\n","\n","\n","# Element-0 of object T which is also the info for all patients at\n","# admission time 9AM\n","print(T[0]) # patients' info at admission time\n","print(T[-1]) # patiens info of T from the tail , patients info at noon\n","\n","\n","# Patient-2 info at 12PM\n","print(T[-1,2])"]},{"cell_type":"markdown","source":["---\n","\n","**Broadcasting**\n","\n","---"],"metadata":{"id":"SW2_NDTCjIL5"}},{"cell_type":"code","source":["a = torch.tensor([1.0, 2.0, 3.0])\n","a = torch.tensor([[1.0, 2.0, 3.0]])\n","a = torch.tensor([[[1.0, 2.0, 3.0]]])\n","print(a)\n","print(a.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q9CJeHb-1Sgk","executionInfo":{"status":"ok","timestamp":1753937845333,"user_tz":-330,"elapsed":11,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"593a65a5-ac47-4769-e3ef-6444565be341"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[1., 2., 3.]]])\n","torch.Size([1, 1, 3])\n"]}]},{"cell_type":"code","source":["# A simple broadcasting example\n","a = torch.tensor([1.0, 2.0, 3.0])\n","b = torch.tensor([4.0])\n","print(a.shape)\n","print(b.shape)\n","print(a-b)"],"metadata":{"id":"1PjnkDnr_qSn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753938153324,"user_tz":-330,"elapsed":67,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"022f012b-8de9-46fd-fa1a-89289f191eda"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3])\n","torch.Size([1])\n","tensor([-3., -2., -1.])\n"]}]},{"cell_type":"code","source":["# # How to add a new axis to a tensor using the unsqueeze() function\n","# print(T)\n","# print(T.shape)\n","T_patient0 = T[:,0,:]\n","print(T_patient0)\n","print(T_patient0.shape)\n","print(\"--------------------\")\n","T_patient0_new = torch.unsqueeze(T_patient0,1)\n","T_patient0_new1 = torch.unsqueeze(T_patient0,0)\n","T_patient0_new2 = torch.unsqueeze(T_patient0,2)\n","\n","\n","print(\"T_new_patient0 is = \",T_patient0_new)\n","print(T_patient0_new.shape)\n","\n","print(\"--------------------\")\n","print(T_patient0_new1)\n","print(T_patient0_new1.shape)\n","\n","\n","print(\"--------------------\")\n","print(T_patient0_new2)\n","print(T_patient0_new2.shape)"],"metadata":{"id":"zhtxw34i_RNt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753940100280,"user_tz":-330,"elapsed":31,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"9c5bbb37-6a19-458f-e2fd-1f98dfc72be4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 74., 128.],\n","        [ 78., 118.],\n","        [ 84., 138.],\n","        [ 82., 126.]])\n","torch.Size([4, 2])\n","--------------------\n","tensor([[[ 74., 128.]],\n","\n","        [[ 78., 118.]],\n","\n","        [[ 84., 138.]],\n","\n","        [[ 82., 126.]]])\n","torch.Size([4, 1, 2])\n","--------------------\n","tensor([[[ 74., 128.],\n","         [ 78., 118.],\n","         [ 84., 138.],\n","         [ 82., 126.]]])\n","torch.Size([1, 4, 2])\n","--------------------\n","tensor([[[ 74.],\n","         [128.]],\n","\n","        [[ 78.],\n","         [118.]],\n","\n","        [[ 84.],\n","         [138.]],\n","\n","        [[ 82.],\n","         [126.]]])\n","torch.Size([4, 2, 1])\n"]}]},{"cell_type":"code","source":["# How different are the patients from patient-0?\n","#T - T[:, 0, :] # does not work for broadcasting\n","# T - T_patient0 # so this doesent work snce the dimensions are not corect\n","T- T_patient0_new\n","\n","\n","#  # How different are the patients compared to their time at admission\n"],"metadata":{"id":"DEPPWVsWjI4X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753939831717,"user_tz":-330,"elapsed":18,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"6ef25e61-dba4-43f7-d0e9-8744446985e1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[  0.,   0.],\n","         [  5., -12.],\n","         [ -3., -12.]],\n","\n","        [[  0.,   0.],\n","         [  4.,   6.],\n","         [ -6.,  10.]],\n","\n","        [[  0.,   0.],\n","         [  0.,  -8.],\n","         [-10., -18.]],\n","\n","        [[  0.,   0.],\n","         [ -6.,  30.],\n","         [  0.,   6.]]])"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"0o6kEXfCpDzo"},"source":["---\n","\n","**Exercise**: interpret $\\texttt{T[:, -1, :]}$\n","\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X6lEPZEWo6wo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753940442073,"user_tz":-330,"elapsed":33,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"a69c7168-e30d-4d3b-dba4-cc3d2c6f1a8b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 71., 116.],\n","        [ 72., 128.],\n","        [ 74., 120.],\n","        [ 82., 132.]])"]},"metadata":{},"execution_count":27}],"source":["# Last patient's info at all timestamps\n","T[:,-1,:]"]},{"cell_type":"markdown","source":["---\n","\n","BroadCasting Excercise\n","\n","---"],"metadata":{"id":"UBz9QLvcACc9"}},{"cell_type":"code","source":["v= torch.tensor([[1.0,2.0,3.0]]) # Here it is 3 object repeatig once\n","print(v)\n","print(v.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F5qefFcGBgYk","executionInfo":{"status":"ok","timestamp":1753943500930,"user_tz":-330,"elapsed":47,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"3a2260de-a0b5-4257-81d6-72d0771c145d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 2., 3.]])\n","torch.Size([1, 3])\n"]}]},{"cell_type":"code","source":["T = torch.randint( -5 , 6 , (4,5,3))\n","print(T)\n","print(T.shape)\n","v= torch.tensor([1.0,2.0,3.0]) #Here it is 1 object repeating 3 times\n","print(v)\n","print(v.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pt4eMA0jARVN","executionInfo":{"status":"ok","timestamp":1753940966130,"user_tz":-330,"elapsed":49,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"0b9242b9-3778-4793-8a0b-d29e51c41df9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[ 4, -1,  5],\n","         [ 1, -5,  0],\n","         [-2,  3,  4],\n","         [ 3,  0,  4],\n","         [-1,  0,  4]],\n","\n","        [[-4, -4, -4],\n","         [-4,  1, -4],\n","         [-5,  0, -3],\n","         [ 4, -4,  1],\n","         [-4,  0, -1]],\n","\n","        [[-1,  2, -3],\n","         [-1,  4,  2],\n","         [-4,  0, -4],\n","         [ 2,  3,  4],\n","         [ 0, -2, -1]],\n","\n","        [[-1,  1,  4],\n","         [-2,  5,  2],\n","         [-3, -3,  2],\n","         [-5, -2,  1],\n","         [-2,  1,  2]]])\n","torch.Size([4, 5, 3])\n","tensor([1., 2., 3.])\n","torch.Size([3])\n"]}]},{"cell_type":"markdown","metadata":{"id":"gc9EJuZQhD9i"},"source":["---\n","\n","$l_2$ norm or the geometric length of a vector denoted as $\\lVert \\mathbf{a}\\rVert$ tells us how long a vector is. In 2-dimensions, $$\\lVert \\mathbf{a}\\rVert_2 = \\sqrt{a_1^2+a_2^2}$$ and in $n$-dimensions, $$\\lVert \\mathbf{a}\\rVert_2 = \\sqrt{a_1^2+a_2^2+\\cdots+a_n^2}.$$\n","\n","![vector norm](https://1drv.ms/i/c/37720f927b6ddc34/IQT817WmpQjlRqZ1R0d5Cfv6AUW6c4robL-gk06i9wmCaFU?width=500)\n","\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OM65UP4_hEso","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753944492489,"user_tz":-330,"elapsed":7,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"8fbf2a21-5edb-4f08-d7a9-0a84808388a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 76., 124.], dtype=torch.float64)\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(145.4373, dtype=torch.float64)"]},"metadata":{},"execution_count":42}],"source":["## l2 norm of a vector\n","x = torch.tensor([76,124],dtype=torch.float64) #dtype - arguments with values\n","print(x)\n","\n","torch.norm(x)"]},{"cell_type":"markdown","metadata":{"id":"SRbanrUmwLX7"},"source":["\n","---\n","\n","**Dot Product of Vectors**\n","\n","A scalar resulting from an elementwise multiplication and addition: $$\\mathbf{a}{\\color{cyan}\\cdot}\\mathbf{b} = {\\color{red}{a_1b_1}}+{\\color{green}{a_2b_2}}+\\cdots+{\\color{magenta}{a_nb_n}}$$\n","\n","The <font color=\"cyan\">dot</font> ${\\color{cyan}\\cdot}$ represents the computation of the dot product.\n","\n","\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s91XY1JZwU2w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753946852381,"user_tz":-330,"elapsed":46,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"89678b8a-8109-40d7-c806-2d422505cb05"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(32., dtype=torch.float64)"]},"metadata":{},"execution_count":49}],"source":["## Dot product of vectors\n","a = torch.tensor([1.0,2.0,3.0],dtype=torch.float64)\n","b = torch.tensor([4.0,5.0,6.0],dtype=torch.float64)\n","torch.dot(a,b)"]},{"cell_type":"markdown","metadata":{"id":"2-b90m-QXyFp"},"source":["---\n","\n","The dot product is a measure of similarity between vectors (or, how aligned they are geometrically).\n","\n","![dot product](https://1drv.ms/i/c/37720f927b6ddc34/IQTbcGSjdbhSTJ7J39d5BCWAAWS6-y5U6J87vHuDWeAqGwM?width=6000)\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3GxZ95uXXz3P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753947094228,"user_tz":-330,"elapsed":45,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"ed8b017c-59c2-493e-98c6-5f77f5ec2bcc"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(10.)\n","tensor(0.)\n","tensor(-5.)\n"]}],"source":["a = torch.tensor([1.0, 2.0])\n","b = torch.tensor([2.0, 4.0])\n","c = torch.tensor([-2.0, 1.0])\n","d = torch.tensor([-1.0, -2.0])\n","print(torch.dot(a, b))\n","print(torch.dot(a, c))\n","print(torch.dot(a, d))"]},{"cell_type":"markdown","metadata":{"id":"U6CS4_8byCs8"},"source":["---\n","\n","Cauchy-Schwarz inequality $-1\\leq\\frac{\\mathbf{x}\\cdot{\\mathbf{y}}}{\\lVert\\mathbf{x}\\rVert_2\\lVert\\mathbf{y}\\rVert_2}\\leq1.$\n","\n","This is a normalized measure of similarity (or extent of alignment) between vectors.\n","\n","Angle between vectors $\\mathbf{x}$ and $\\mathbf{y} = \\cos^{-1}\\left(\\frac{\\mathbf{x}\\cdot{\\mathbf{y}}}{\\lVert\\mathbf{x}\\rVert_2\\lVert\\mathbf{y}\\rVert_2}\\right).$\n","\n","![angle](https://1drv.ms/i/c/37720f927b6ddc34/IQQ03G17kg9yIIA3WokBAAAAAQi8FPV9YCebl5WnyEKJ3vg?width=213&height=400)\n","\n","\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q4UhBnPUx7TV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754006244626,"user_tz":-330,"elapsed":45,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"2a13efcb-29bf-4d7b-fbbb-49c0cb036b08"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(1.4142)\n","tensor(0.8000)\n","radians: tensor(0.6435)\n","Degree: tensor(36.8699)\n"]}],"source":["x = torch.tensor([1.0, 2.0])\n","y = torch.tensor([2.0, 1.0])\n","# pro_norm = torch.norm(x * y)\n","\n","#Linear difference between x & y\n","print(torch.norm(x - y))\n","\n","#-------------------------------------\n","# Angle between x and y in radians\n","dot_product = torch.dot(x,y)\n","norm_x = torch.norm(x)\n","norm_y = torch.norm(y)\n","\n","res =  (dot_product/(norm_x * norm_y))\n","print(res)\n","\n","radians = torch.acos(res)\n","print(\"radians:\", radians)\n","\n","#--------------------------------------\n","# Angle between x and y in degrees\n","deg = torch.rad2deg(radians)\n","# or\n","\n","deg = ((180/torch.pi)* radians)\n","print(\"Degree:\",deg)"]},{"cell_type":"markdown","metadata":{"id":"1bnmEkg3Tctx"},"source":["---\n","\n","Application of the Cauchy-Schwarz inequality: is \"Cricket without Tendulkar\" same as \"Football without Messi\"?\n","\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KrmCknO5TkNZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754006557123,"user_tz":-330,"elapsed":29,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"fd78e4f5-c5b1-4615-80a5-39d0410ecbcf"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([-0.7716,  0.4127, -1.7260, -0.1045, -1.1476, -0.8547, -1.0890, -0.0834,\n","         0.6235, -1.6782, -0.2488, -0.4920,  0.1876, -1.6710,  0.6118,  0.4278,\n","         1.0566,  0.9158, -0.0330, -0.0442,  0.2003, -0.3374,  0.3107,  1.3784,\n","        -1.1369, -0.5745, -0.7069,  0.4155, -0.2894,  0.5448,  1.0493,  0.6273,\n","        -0.8105, -1.2772, -0.0261,  0.5396, -0.1407, -0.7382, -0.3049, -1.1813,\n","         0.0565, -0.9936, -0.9114, -0.0929,  0.5354,  0.2626, -0.6303,  0.6447,\n","         0.7784,  0.1510], dtype=torch.float64)\n","<class 'torch.Tensor'>\n","tensor([-2.0690,  0.6680, -1.0775,  0.7996, -0.2711, -0.2629, -0.8810,  0.3775,\n","        -0.1087, -2.4733, -0.2345, -0.5844,  0.1040, -0.5267, -0.0303,  0.2378,\n","         0.1917,  1.6034, -0.4298,  0.5906,  0.5980, -0.6708,  0.4589,  1.4538,\n","        -1.1564, -1.6353, -1.1248, -0.2088, -0.0081,  0.2555,  1.9204,  0.3005,\n","         0.1995, -0.6752, -0.1523,  0.1328, -0.2949, -0.5541, -0.3099, -0.3455,\n","        -0.7260, -1.2050, -0.4504,  0.5183,  0.1245,  0.7876, -1.1340,  0.9137,\n","        -0.2805,  0.7674], dtype=torch.float64)\n","tensor([ 1.2974, -0.2554, -0.6485, -0.9041, -0.8765, -0.5918, -0.2080, -0.4609,\n","         0.7322,  0.7951, -0.0143,  0.0924,  0.0835, -1.1443,  0.6421,  0.1901,\n","         0.8649, -0.6876,  0.3968, -0.6348, -0.3977,  0.3334, -0.1482, -0.0754,\n","         0.0195,  1.0609,  0.4180,  0.6243, -0.2812,  0.2894, -0.8711,  0.3268,\n","        -1.0100, -0.6021,  0.1262,  0.4068,  0.1543, -0.1841,  0.0050, -0.8358,\n","         0.7825,  0.2114, -0.4610, -0.6112,  0.4109, -0.5250,  0.5037, -0.2689,\n","         1.0589, -0.6164], dtype=torch.float64)\n","tensor(0.7371, dtype=torch.float64)\n","tensor(0.7420, dtype=torch.float64) tensor(42.5126, dtype=torch.float64)\n"]}],"source":["a = torch.tensor(model['cricket'] - model['tendulkar'] ,dtype = torch.float64) #converting from nump.ndarray to tensor\n","b = torch.tensor(model['football'] - model['messi'] ,dtype = torch.float64)\n","print(a)\n","print(type(a))\n","print(b)\n","\n","# How different is cricket-without-tendulkar from\n","# football-without-messi?\n","print(a-b)\n","\n","dot_product = torch.dot(a,b)\n","norm_a = torch.norm(a)\n","norm_b = torch.norm(b)\n","\n","res =  (dot_product/(norm_a * norm_b))\n","print(res)\n","r = torch.acos(res)\n","deg = torch.rad2deg(r)\n","print(r, deg)"]},{"cell_type":"code","source":["c = torch.tensor(model['tennis'] - model['federer'] , dtype=torch.float64)\n","\n","#Angle difference between a and b in degrees\n","print((180/torch.pi)* (torch.acos(torch.dot(a,c)/(torch.norm(a)*torch.norm(c)))))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JPKQLA2U8eE1","executionInfo":{"status":"ok","timestamp":1754027265355,"user_tz":-330,"elapsed":18,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"fce3c54e-86bf-4341-c6a1-ace33080a279"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(53.1156, dtype=torch.float64)\n"]}]},{"cell_type":"markdown","metadata":{"id":"ayzM_0_synRF"},"source":["\n","---\n","\n","**Hadamard Product of Vectors**\n","\n","A vector resulting from an elementwise multiplication: $$\\mathbf{a}{\\color{cyan}\\otimes}\\mathbf{b} = \\begin{bmatrix}{\\color{red}{a_1\\times b_1}}\\\\{\\color{green}{a_2\\times b_2}}\\\\\\vdots\\\\{\\color{magenta}{a_n\\times b_n}}\\end{bmatrix}.$$\n","\n","The <font color=\"cyan\">$\\otimes$</font> represents the computation of the Hadamard product.\n","\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UPojS0rIzR8p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754027937686,"user_tz":-330,"elapsed":6,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"5bbb10af-1dec-41af-b62a-f53fa5ccca82"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 4., 10., 18.], dtype=torch.float64)\n"]}],"source":["## Hadamard product\n","a = torch.tensor([1.0, 2.0, 3.0],dtype=torch.float64)\n","b = torch.tensor([4.0, 5.0, 6.0],dtype=torch.float64)\n","\n","# Element-wise multiplication (Hadamard product)\n","# print(a*b)\n","print(torch.mul(a,b))"]},{"cell_type":"markdown","metadata":{"id":"oruyV_EjhqCR"},"source":["---\n","\n","A matrix-vector product is simply a sequence of dot products of the rows of the matrix (seen as vectors) with the vector\n","\n","![matvec product](https://1drv.ms/i/c/37720f927b6ddc34/IQQ1cQ8fZdFmS4cnGkBlsZbAAaL2zMtzWdjHe-HCMt4UTA0?width=700)\n","\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A_IScSWzhpi7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754028542442,"user_tz":-330,"elapsed":9,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"2b047ff0-36ce-4daa-efd1-013db7dded0c"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(0.)\n","tensor(0.)\n","tensor([0., 0.])\n"]}],"source":["## Matrix-vector product\n","A = torch.tensor([[1.0, 2.0, 4.0],\n","                  [2.0, -1.0, 3.0]])\n","x = torch.tensor([4.0, 2.0, -2.0])\n","\n","##Dot product (anbgle in radians)\n","print(torch.dot(A[0],x))\n","print(torch.dot(A[1],x))\n","\n","# Matrix-vector multiplication\n","print(torch.matmul(A,x))"]},{"cell_type":"markdown","metadata":{"id":"uTnGSJ3vT4EN"},"source":["---\n","\n","Here we create a simple sentence in English and tokenize it\n","\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pQ73kkevT5L3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754291086168,"user_tz":-330,"elapsed":322,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"e7d25f49-084f-430e-a3a0-f87f03883d36"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}],"source":["sentence = 'i swam quickly across the river to get to the other bank'\n","nltk.download('punkt_tab')"]},{"cell_type":"markdown","metadata":{"id":"M40pqI8UUbX4"},"source":["---\n","\n","Generate the word embeddings for the tokens and store them in a matrix $\\mathbf{X}$ such that each row of the matrix corresponds to a token.\n","\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1mKKVRyxUh5V"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"mVoJRc6kUtI2"},"source":["---\n","\n","The similarity between each pair of words represented in the word embeddings matrix $\\mathbf{X}_\\mathrm{word}$ is the matrix-matrix product $\\mathbf{X}_\\mathrm{word}\\mathbf{X}_\\mathrm{word}^\\mathrm{T}.$\n","\n","---"]},{"cell_type":"code","source":[],"metadata":{"id":"4TTyV8z3AYrm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Z0pZQisxtY-"},"source":["---\n","\n","A matrix-matrix product is simply a sequence of matrix-vector products.\n","\n","![matmatprod](https://1drv.ms/i/c/37720f927b6ddc34/IQQ-B3z7tbWHQqBrW9k2ElDVAUc5fWzM24txLkgBK7f8Yac?width=550)\n","\n","\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YSg1brJ9yKnM"},"outputs":[],"source":["A= torch.tensor([[1.0,2.0,3.0],[]])\n","## Matrix-matrix product\n","print( )"]},{"cell_type":"markdown","source":["Exercise: Matrix Mul"],"metadata":{"id":"08rAZ4fCchN-"}},{"cell_type":"code","source":["D = torch.tensor([[1,-2,1,0,0,0],[0,1,-2,1,0,0],[0,0,1,-2,1,0,],[0,0,0,1,-2,1]],dtype=torch.float64)\n","print(D)\n","print(D.type())\n","print(D.dtype)\n","#[10,-5,15,-10,10,-15]\n","x= torch.tensor([10,-5,15,-10,10,-15],dtype=torch.float64)\n","print(x)\n","Dx = torch.matmul(D,x)\n","print(\"Dx:\",Dx)\n","print(torch.norm(Dx))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wdnt5jmicnPk","executionInfo":{"status":"ok","timestamp":1754033699041,"user_tz":-330,"elapsed":17,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"9350d4e7-cc51-4dbd-8fc2-930348590400"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[  1., -32.,   1.,   0.,   0.,   0.],\n","        [  0.,   1., -32.,   1.,   0.,   0.],\n","        [  0.,   0.,   1., -32.,   1.,   0.],\n","        [  0.,   0.,   0.,   1., -32.,   1.]], dtype=torch.float64)\n","torch.DoubleTensor\n","torch.float64\n","tensor([ 10.,  -5.,  15., -10.,  10., -15.], dtype=torch.float64)\n","Dx: tensor([ 35., -45.,  45., -45.], dtype=torch.float64)\n","tensor(85.4400, dtype=torch.float64)\n"]}]},{"cell_type":"code","source":["D = torch.tensor([[0,0,0,0,1],[1,0,0,0,0],[0,1,0,0,0],[0,0,1,0,0],[0,0,0,1,0]],dtype=torch.float64)\n","print(torch.matmul(D,D))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kenpyHJ1jpLO","executionInfo":{"status":"ok","timestamp":1754034471291,"user_tz":-330,"elapsed":24,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"eba629c1-c5f6-4c65-f778-b4303660f1b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0., 0., 0., 1., 0.],\n","        [0., 0., 0., 0., 1.],\n","        [1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 0., 1., 0., 0.]], dtype=torch.float64)\n"]}]},{"cell_type":"code","source":["# Example 1: Explicit 5x5 matrix\n","matrix = torch.tensor([\n","    [1, 2, 3, 4, 5],\n","    [6, 7, 8, 9, 10],\n","    [11, 12, 13, 14, 15],\n","    [16, 17, 18, 19, 20],\n","    [21, 22, 23, 24, 25]\n","], dtype=torch.float32)\n","\n","print(matrix)\n","print(\"Shape:\", matrix.shape)  # Should print: torch.Size([5, 5])\n"],"metadata":{"id":"QbXNQ2OSkk--"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","Matrix-matrix product using patient data matrix and a weights matrix:\n","\n","![patient dataset](https://1drv.ms/i/s!AjTcbXuSD3I3hspfrgklysOtJMOjaA?embed=1&width=800)\n","\n","$$\\mathbf{Z} = \\mathbf{XW}.$$\n","\n","---"],"metadata":{"id":"h5cHHVQOuT0z"}},{"cell_type":"code","source":["# Patients data matrix\n","X = torch.tensor([[72, 120, 37.3, 104, 32.5],\n","                 [85, 130, 37.0, 110, 14],\n","                 [68, 110, 38.5, 125, 34],\n","                 [90, 140, 38.0, 130, 26],\n","                 [84, 132, 38.3, 146, 30],\n","                 [78, 128, 37.2, 102, 12]],dtype = torch.float64)\n","print(f'Patient data matrix X:\\n {X}')\n","\n","# Weights matrix\n","W =torch.tensor([[-0.1,0.5,0.3],\n","                 [0.9,0.3,0.5],\n","                 [-1.5,0.4,0.1],\n","                 [0.1,0.1,-1.0],\n","                 [-1.2,0.5,-0.8]\n","                 ],dtype = torch.float64)\n","print(f'Weights matrix:\\n {W}')\n","\n","# Raw scores matrix (matrix-matrix multiplication)\n","Z = torch.matmul(X,W)\n","print(f'Raw zcores matrix:\\n {Z}')\n","# The raw scores are also referred to as the logits"],"metadata":{"id":"njrrw_MnuUpo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754402306109,"user_tz":-330,"elapsed":281,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"b2a1d5a5-d02f-45da-97ee-865cbafd902b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Patient data matrix X:\n"," tensor([[ 72.0000, 120.0000,  37.3000, 104.0000,  32.5000],\n","        [ 85.0000, 130.0000,  37.0000, 110.0000,  14.0000],\n","        [ 68.0000, 110.0000,  38.5000, 125.0000,  34.0000],\n","        [ 90.0000, 140.0000,  38.0000, 130.0000,  26.0000],\n","        [ 84.0000, 132.0000,  38.3000, 146.0000,  30.0000],\n","        [ 78.0000, 128.0000,  37.2000, 102.0000,  12.0000]],\n","       dtype=torch.float64)\n","Weights matrix:\n"," tensor([[-0.1000,  0.5000,  0.3000],\n","        [ 0.9000,  0.3000,  0.5000],\n","        [-1.5000,  0.4000,  0.1000],\n","        [ 0.1000,  0.1000, -1.0000],\n","        [-1.2000,  0.5000, -0.8000]], dtype=torch.float64)\n","Raw zcores matrix:\n"," tensor([[ 16.2500, 113.5700, -44.6700],\n","        [ 47.2000, 114.3000, -27.0000],\n","        [  6.1500, 111.9000, -72.9500],\n","        [ 41.8000, 128.2000, -50.0000],\n","        [ 31.5500, 126.5200, -74.9700],\n","        [ 47.4000, 108.4800, -20.4800]], dtype=torch.float64)\n"]}]},{"cell_type":"markdown","source":["---\n","\n","**Version-1** view of the matrix-matrix product $\\mathbf{Z} = \\mathbf{XW}$:\n","\n","*What a particular neuron understands about a particular patient.*\n","\n","![matrix-matrix product version-1](https://1drv.ms/i/c/37720f927b6ddc34/IQQdAOCwtndURKA-h4yvpTqlAYjBjlcweRSeMYkPvf7dwmQ?width=660)\n","\n","$$\\begin{align*}[\\mathbf{Z}]_{i,j} &= (i,j)\\text{-th element of }\\mathbf{Z}\\\\&=\\text{what the }j\\text{th neuron learns about the } i\\text{th patient}\\\\&=\\mathbf{x}^{(i)}\\cdot\\mathbf{w}_j\\\\& = {\\mathbf{x}^{(i)}}^\\mathrm{T}\\mathbf{w}_j\\\\\\Rightarrow \\underbrace{[\\mathbf{Z}]_{{\\color{yellow}0},{\\color{cyan}2}}}_{{\\color{yellow}0}\\text{th patient},\\,{\\color{cyan}2}\\text{nd neuron}} &= \\mathbf{x}^{({\\color{yellow}0})}\\cdot\\mathbf{w}_{{\\color{cyan}2}}\\\\ &= \\begin{bmatrix}72\\\\120\\\\37.3\\\\104\\\\32.5\\end{bmatrix}\\cdot\\begin{bmatrix}0.3\\\\0.5\\\\0.1\\\\-1.0\\\\-0.8\\end{bmatrix}\\\\ &= -44.67.\\end{align*}$$\n","\n","---"],"metadata":{"id":"qWigLvBRucwi"}},{"cell_type":"code","source":["X[0, :]\n","W[:, 2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b9VD14_18Vx_","executionInfo":{"status":"ok","timestamp":1754291901218,"user_tz":-330,"elapsed":7,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"1eb3d82d-c933-440d-a645-3601ea2b933e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 0.3000,  0.5000,  0.1000, -1.0000, -0.8000], dtype=torch.float64)"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["## The (0, 2)-th element of the matrix-matrix product XW\n","#we tend to forget how indexing works in 2d matrix of tensor or rank-3 tensor\n","X_0 = X[0]\n","print(X_0)\n","W_2 = W[:,2]\n","print(W_2)\n","Matrixmul= torch.dot(X_0,W_2)\n","print(Matrixmul)"],"metadata":{"id":"q-rGT4NaueRk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754292574626,"user_tz":-330,"elapsed":17,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"57ca19fc-0889-4c24-a0fd-e9f4c9c744bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 72.0000, 120.0000,  37.3000, 104.0000,  32.5000], dtype=torch.float64)\n","tensor([ 0.3000,  0.5000,  0.1000, -1.0000, -0.8000], dtype=torch.float64)\n","tensor(-44.6700, dtype=torch.float64)\n"]}]},{"cell_type":"markdown","source":["---\n","\n","**Version-2** view of the matrix-matrix product $\\mathbf{Z} = \\mathbf{XW}$:\n","\n","*What a particular neuron understands about all the patients.*\n","\n","![matrix-matrix product version-2](https://1drv.ms/i/c/37720f927b6ddc34/IQRm1-w-6TG0R4C4J4BizyzyAWIbcHzbEjgmx-0JFREdHsE?width=660)\n","\n","$$\\begin{align*}\\mathbf{z}_j &= \\mathbf{X}\\mathbf{w}_j\\\\&=\\text{what the } j\\text{th neuron learns about the all the patients}\\\\&=w_{j,0}\\times\\textbf{HR}+w_{j,1}\\times\\textbf{BP}+w_{j,2}\\times\\textbf{Temp}+w_{j,3}\\times\\textbf{Sugar}+w_{j,4}\\times\\textbf{Vitamin D}\\\\&= w_{j,0}\\mathbf{x}_0+w_{j,1}\\mathbf{x}_1+w_{j,2}\\mathbf{x}_2+w_{j,3}\\mathbf{x}_3+w_{j,4}\\mathbf{x}_4\\\\\\Rightarrow\\underbrace{\\mathbf{z}_{{\\color{cyan}0}}}_{{\\color{cyan}0}\\text{th neuron understanding}} &= \\underbrace{\\mathbf{X}}_{\\color{yellow}{\\text{all patients}}}\\ \\underbrace{\\mathbf{w}_{{\\color{cyan}0}}}_{{\\color{cyan}0}\\text{th neuron weights}}\\\\&= {\\color{cyan}{-0.1}}\\times\\begin{bmatrix}{\\color{yellow}{72}}\\\\{\\color{yellow}{85}}\\\\{\\color{yellow}{68}}\\\\{\\color{yellow}{90}}\\\\{\\color{yellow}{84}}\\\\{\\color{yellow}{78}}\\end{bmatrix}+{\\color{cyan}{0.9}}\\times\\begin{bmatrix}{\\color{yellow}{120}}\\\\{\\color{yellow}{130}}\\\\{\\color{yellow}{110}}\\\\{\\color{yellow}{140}}\\\\{\\color{yellow}{132}}\\\\{\\color{yellow}{128}}\\end{bmatrix}+({\\color{cyan}{-1.5}})\\times\\begin{bmatrix}{\\color{yellow}{37.3}}\\\\{\\color{yellow}{37.0}}\\\\{\\color{yellow}{38.5}}\\\\{\\color{yellow}{38.0}}\\\\{\\color{yellow}{38.3}}\\\\{\\color{yellow}{37.2}}\\end{bmatrix}+{\\color{cyan}{0.1}}\\times\\begin{bmatrix}{\\color{yellow}{104}}\\\\{\\color{yellow}{110}}\\\\{\\color{yellow}{125}}\\\\{\\color{yellow}{130}}\\\\{\\color{yellow}{146}}\\\\{\\color{yellow}{102}}\\end{bmatrix}+({\\color{cyan}{-1.2}})\\times\\begin{bmatrix}{\\color{yellow}{32.5}}\\\\{\\color{yellow}{14}}\\\\{\\color{yellow}{34}}\\\\{\\color{yellow}{26}}\\\\{\\color{yellow}{30}}\\\\{\\color{yellow}{12}}\\end{bmatrix}\\\\&=\\begin{bmatrix}16.25\\\\47.20\\\\6.15\\\\41.80\\\\31.55\\\\47.40\\end{bmatrix}.\\end{align*}$$\n","\n","\n","\n","---"],"metadata":{"id":"RzqALUS-ugoU"}},{"cell_type":"code","source":["## The 0-th column of the matrix-matrix product XW\n","neuron_0 = W[:,0]\n","All_patients = X\n","print(All_patients.shape)\n","matmull = torch.matmul(All_patients,neuron_0)\n","print(matmull)"],"metadata":{"id":"sJbmVTzuukEh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754292841837,"user_tz":-330,"elapsed":44,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"f1125252-d3a3-46c1-cb14-a0bf0eacbdfa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([6, 5])\n","tensor([16.2500, 47.2000,  6.1500, 41.8000, 31.5500, 47.4000],\n","       dtype=torch.float64)\n"]}]},{"cell_type":"markdown","source":["---\n","\n","**Version-3** view of the matrix-matrix product $\\mathbf{Z} = \\mathbf{XW}$:\n","\n","*What all neurons understand about a particular patient.*\n","\n","![matrix-matrix product version-3](https://1drv.ms/i/c/37720f927b6ddc34/IQRfO-qEJQ9mQYLH_f-lyjeQAaWV4FrDjTjaEHJpPB1PmCg?width=660)\n","\n","$$\\begin{align*}{\\mathbf{z}^{(i)}}^\\mathrm{T}&={\\mathbf{x}^{(i)}}^\\mathrm{T}\\mathbf{W}\\\\&= \\text{what is learned about the }i\\text{th patient by all the neurons}\\\\&=i\\text{th HR }\\times{\\mathbf{w}^{(0)}}^\\mathrm{T}+i\\text{th BP }\\times{\\mathbf{w}^{(1)}}^\\mathrm{T}+i\\text{th Temp }\\times{\\mathbf{w}^{(2)}}^\\mathrm{T}+i\\text{th Sugar }\\times{\\mathbf{w}^{(3)}}^\\mathrm{T}+i\\text{th Vitamin D }\\times{\\mathbf{w}^{(4)}}^\\mathrm{T}\\\\&=x^{(i)}_0\\times{\\mathbf{w}^{(0)}}^\\mathrm{T}+x^{(i)}_1\\times{\\mathbf{w}^{(1)}}^\\mathrm{T}+x^{(i)}_2\\times{\\mathbf{w}^{(2)}}^\\mathrm{T}+x^{(i)}_3\\times{\\mathbf{w}^{(3)}}^\\mathrm{T}+x^{(i)}_4\\times{\\mathbf{w}^{(4)}}^\\mathrm{T}\\\\\\underbrace{\\Rightarrow{{\\mathbf{z}^{({\\color{yellow}0})}}^\\mathrm{T}}}_{{\\color{yellow}{0}}\\text{th patient understanding}}&=\\underbrace{{{\\mathbf{x}^{({\\color{yellow}0})}}^\\mathrm{T}}}_{{\\color{yellow}{0}}\\text{th patient}}\\ \\underbrace{\\mathbf{W}}_{{\\color{cyan}{\\text{all neurons}}}}\\\\ &= {\\color{yellow}{72}}\\times\\begin{bmatrix}{\\color{cyan}{-0.1}} & {\\color{cyan}{0.5}} & {\\color{cyan}{0.3}}\\end{bmatrix} \\\\&+ {\\color{yellow}{120}}\\times\\begin{bmatrix}{\\color{cyan}{0.9}} & {\\color{cyan}{0.3}} & {\\color{cyan}{0.5}}\\end{bmatrix}\\\\&+{\\color{yellow}{37.3}}\\times\\begin{bmatrix}{\\color{cyan}{-1.5}} & {\\color{cyan}{0.4}} & {\\color{cyan}{0.1}}\\end{bmatrix}\\\\&+{\\color{yellow}{104}}\\times\\begin{bmatrix}{\\color{cyan}{0.1}} & {\\color{cyan}{0.1}} & {\\color{cyan}{-1.0}}\\end{bmatrix}\\\\&+{\\color{yellow}{32.5}}\\times\\begin{bmatrix}{\\color{cyan}{-1.2}} & {\\color{cyan}{0.5}} & {\\color{cyan}{-0.8}}\\end{bmatrix}\\\\&=\\begin{bmatrix}16.25 & 113.57 & 7.33\\end{bmatrix}.\\end{align*}$$\n","\n","\n","---"],"metadata":{"id":"jrQE8b2xukgE"}},{"cell_type":"code","source":["## The 0-th row of the matrix-matrix product XW\n","N_n = W\n","P_0 = X[0,:]\n","matmull = torch.matmul(P_0,N_n)\n","print(matmull)"],"metadata":{"id":"o-Nv7NOLun5e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754292331858,"user_tz":-330,"elapsed":52,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"fdc9570c-385a-4310-ffaf-3002a8b2ce7c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 16.2500, 113.5700, -44.6700], dtype=torch.float64)\n"]}]},{"cell_type":"markdown","source":["---\n","\n","The softmax function: takes a $k$-vector $\\mathbf{z}$ as input and returns a vector $\\mathbf{a}$ of the same shape as the output which is referred to as the softmax-activated scores.\n","\n","$\\begin{align*}\\mathbf{a}&=\\text{softmax}(\\mathbf{z})=\\begin{bmatrix}\\dfrac{e^{z_1}}{e^{z_1}+e^{z_2}+\\cdots+e^{z_k}}\\\\\\dfrac{e^{z_2}}{e^{z_1}+e^{z_2}+\\cdots+e^{z_k}}\\\\\\vdots\\\\\\dfrac{e^{z_k}}{e^{z_1}+e^{z_2}+\\cdots+e^{z_k}}\\end{bmatrix}.\\end{align*}$\n","\n","In the following example, we consider a raw scores vector $\\mathbf{z}$ with 3 components which leads to the softmax-activated scores vectors $\\mathbf{a}$ which can be interpreted as the predicted probabilities that the sample belongs to each one of the output classes:\n","\n","![softmax](https://1drv.ms/i/s!AjTcbXuSD3I3hscmdol7J2G4GDo5WQ?embed=1&width=660)\n","\n","\n","---"],"metadata":{"id":"NLWq_5p3usNO"}},{"cell_type":"code","source":["# Raw scores matrix (matrix-matrix multiplication)\n","Z = torch.matmul(X,W)\n","print(f'Raw zcores matrix:\\n {Z}')\n","# The raw scores are also referred to as the logits\n","\n","#calculate the softmax scores\n","softmax = torch.nn.Softmax(dim=1)\n","A = softmax(Z)\n","print(f\"The softmax values are :\\n {A}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sIEvpcTkr4df","executionInfo":{"status":"ok","timestamp":1754120101663,"user_tz":-330,"elapsed":23,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"e44e2760-9298-4573-b24f-0e05ce445b6d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Raw zcores matrix:\n"," tensor([[ 16.2500, 113.5700, -44.6700],\n","        [ 47.2000, 114.3000, -27.0000],\n","        [  6.1500, 111.9000, -72.9500],\n","        [ 41.8000, 128.2000, -50.0000],\n","        [ 31.5500, 126.5200, -74.9700],\n","        [ 47.4000, 108.4800, -20.4800]], dtype=torch.float64)\n","The softmax values are :\n"," tensor([[5.4258e-43, 1.0000e+00, 1.8934e-69],\n","        [7.2250e-30, 1.0000e+00, 4.3071e-62],\n","        [1.1840e-46, 1.0000e+00, 5.2561e-81],\n","        [2.9989e-38, 1.0000e+00, 4.0618e-78],\n","        [5.6892e-42, 1.0000e+00, 3.1189e-88],\n","        [2.9737e-27, 1.0000e+00, 9.8488e-57]], dtype=torch.float64)\n"]}]},{"cell_type":"code","source":["z= torch.tensor([1.0,2.0,3.0],dtype= torch.float64)\n","print(z)\n","softmax = torch.nn.Softmax(dim = 0)\n","a = softmax(z)\n","print(a)\n","print(torch.sum(a))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2W_HvZ6adVqT","executionInfo":{"status":"ok","timestamp":1754283968072,"user_tz":-330,"elapsed":140,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"c33760ac-26d9-477c-9ed6-7740bc0ce985"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1., 2., 3.], dtype=torch.float64)\n","tensor([0.0900, 0.2447, 0.6652], dtype=torch.float64)\n","tensor(1.0000, dtype=torch.float64)\n"]}]},{"cell_type":"markdown","source":["---\n","\n","\n","Standardizatio of data to get rid of the effect of units\n","\n","\n","---"],"metadata":{"id":"To_1NZZwmKde"}},{"cell_type":"code","source":["#Heart rate vector\n","a = X[:,0]\n","print(f\"Heart rate vector:\\n {a}\")\n","\n","# BP vector\n","b = X[:,1]\n","# print(f\"Blood pressure vector:\\n {b}\")\n","# print(b)\n","\n","#Average Heart rate\n","avg_heart = torch.mean(a)\n","print(f\"The Average Heart rate: \\n {avg_heart}\")\n","\n","# #Average Blood pressure\n","# print(torch.mean(b))\n","\n","#we are doing broadcasting and finding out values called-> in plain english we can take first value and say the first value s -7.5 times lesser than avg heart rate value\n","# Mean-centerd heart rate vector or thr de-meaned heart rate vector\n","# deviations in the heart rate vector\n","a_mc = a - avg_heart\n","print(f\"Mean-centered/Deviation in heart rate vector:\\n {a_mc}\")\n","\n","#Average of the components of the mean-centered vector, This is used to check if the avg done is right and centered\n","# avg_a_mc = torch.mean(a_mc)\n","# print(avg_a_mc)\n","\n","#to find the deviation among all the aptients->\n","#The ######squared deviation vector\n","# Why we do thi?-> we do this because we need only the magnitude of the deviation not the sign where it deviates\n","sd_a_mc = a_mc**2\n","print(f\"Squared-Deviation in heart rate vector:\\n {sd_a_mc}\")\n","\n","#The average of the squared deviation vector a k a the variance in the heart rate\n","#This is also called the #####variance\n","v = torch.mean(sd_a_mc)\n","print(f\"The average of the squared deviation vector:\\n {v}\")\n","\n","#Square root of thr avg of the squared deviation vector\n","# WHich is the same as the square root of the variance\n","#This the ######standard deviation in the heart rate\n","s = torch.sqrt(v)\n","print(f\"Standard deviation:\\n {s}\")\n","\n","# Standardized Heart-Rate Vector a.k.a the z-scores of the heart-rate\n","z = a_mc / s\n","print(f\"Standardized Heart-rate Vector: \\n {z}\")\n","#"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8k-h5kKKmVvu","executionInfo":{"status":"ok","timestamp":1754402322846,"user_tz":-330,"elapsed":42,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"47ee104b-4c63-4195-e9c7-1872707f5ac9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Heart rate vector:\n"," tensor([72., 85., 68., 90., 84., 78.], dtype=torch.float64)\n","The Average Heart rate: \n"," 79.5\n","Mean-centered/Deviation in heart rate vector:\n"," tensor([ -7.5000,   5.5000, -11.5000,  10.5000,   4.5000,  -1.5000],\n","       dtype=torch.float64)\n","Squared-Deviation in heart rate vector:\n"," tensor([ 56.2500,  30.2500, 132.2500, 110.2500,  20.2500,   2.2500],\n","       dtype=torch.float64)\n","The average of the squared deviation vector:\n"," 58.583333333333336\n","Standard deviation:\n"," 7.65397500213669\n","Standardized Heart-rate Vector: \n"," tensor([-0.9799,  0.7186, -1.5025,  1.3718,  0.5879, -0.1960],\n","       dtype=torch.float64)\n"]}]},{"cell_type":"markdown","source":["---\n","\n","One Hot encoding to the true output labels\n","\n","![patient dataset](https://1drv.ms/i/s!AjTcbXuSD3I3hspfrgklysOtJMOjaA?embed=1&width=800)\n","\n","\n","---"],"metadata":{"id":"-zU7nHd96ZTV"}},{"cell_type":"code","source":["from tkinter.constants import Y\n","# The following does not work in pytorch\n","# y =  torch.tensor(['non-diabetic','diabetic'])\n","\n","# Create a numpy array (equivalent to a rank-1 tensor in Pytorch\n","# which itself is equivalent to a vector in pen & paper )\n","y = np.array(['non-diabetic',\n","              'diabetic',\n","              'non-diabetic',\n","              'pre-diabetic',\n","              'diabetic',\n","              'pre-diabetic'])\n","print(y)\n","print(type(y))\n","print(y.shape)\n","a = y.reshape(-1,1)\n","print(\"---------------------------------\")\n","print(a)\n","print(type(a))\n","print(a.shape)\n","\n","print(\"---------------------------------\")\n","\n","# Creating one-hot encoder object\n","ohe = OneHotEncoder(sparse_output= False)\n","# Create the one-hot encoded true output labels matrix\n","Y = torch.tensor(ohe.fit_transform(a),dtype=torch.float64)\n","print(Y)\n","print(type(Y))\n","print(Y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c1iaO4vw9nhb","executionInfo":{"status":"ok","timestamp":1754402334922,"user_tz":-330,"elapsed":17,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"19d52209-5dac-4e9c-f0f0-bc60537c8fea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['non-diabetic' 'diabetic' 'non-diabetic' 'pre-diabetic' 'diabetic'\n"," 'pre-diabetic']\n","<class 'numpy.ndarray'>\n","(6,)\n","---------------------------------\n","[['non-diabetic']\n"," ['diabetic']\n"," ['non-diabetic']\n"," ['pre-diabetic']\n"," ['diabetic']\n"," ['pre-diabetic']]\n","<class 'numpy.ndarray'>\n","(6, 1)\n","---------------------------------\n","tensor([[0., 1., 0.],\n","        [1., 0., 0.],\n","        [0., 1., 0.],\n","        [0., 0., 1.],\n","        [1., 0., 0.],\n","        [0., 0., 1.]], dtype=torch.float64)\n","<class 'torch.Tensor'>\n","torch.Size([6, 3])\n"]}]},{"cell_type":"code","source":["# Standardize the Data\n","sc = StandardScaler() # create a standard scalar object\n","X_std = torch.tensor(sc.fit_transform(X),dtype=torch.float64) # That is what calculates z - scores\n","print(f\"The standardized data matrix or Standardized patient vector:\\n {X_std}\") #here we convert patients data to std patients vectorvector\n","\n","# The one-hpt encoded true output labels matrix\n","print(f\"The one-hot encoded true output labels matrix:\\n {Y}\")\n","\n","# Calculate the raw scores usin the srd data matrix\n","#  and the weights matrix\n","print(f\"The weights matrix is:\\n {W}\")\n","\n","Z = torch.matmul(X_std,W)\n","print(f\"The raw scores matrix is:\\n {Z}\")\n","\n","# calculate the softmax avctivated scores matrix\n","softmax = torch.nn.Softmax(dim=1)\n","A=softmax(Z)\n","print(f\"The softmax-activated raw scores:\\n{A}\")\n","\n","# The Avergae loss we got\n","print(f\"The average traning loss :\\n{torch.mean(-torch.log(torch.sum(Y*A,dim = 1)))}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"colYbbu5F0T0","executionInfo":{"status":"ok","timestamp":1754402361242,"user_tz":-330,"elapsed":94,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"3c002de0-ab7e-42a7-8fcc-ee116de74b09"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The standardized data matrix or Standardized patient vector:\n"," tensor([[-0.9799, -0.7019, -0.7238, -0.9871,  0.8920],\n","        [ 0.7186,  0.3509, -1.2449, -0.6050, -1.2374],\n","        [-1.5025, -1.7547,  1.3607,  0.3503,  1.0647],\n","        [ 1.3718,  1.4037,  0.4922,  0.6687,  0.1439],\n","        [ 0.5879,  0.5615,  1.0133,  1.6876,  0.6043],\n","        [-0.1960,  0.1404, -0.8975, -1.1144, -1.4676]], dtype=torch.float64)\n","The one-hot encoded true output labels matrix:\n"," tensor([[0., 1., 0.],\n","        [1., 0., 0.],\n","        [0., 1., 0.],\n","        [0., 0., 1.],\n","        [1., 0., 0.],\n","        [0., 0., 1.]], dtype=torch.float64)\n","The weights matrix is:\n"," tensor([[-0.1000,  0.5000,  0.3000],\n","        [ 0.9000,  0.3000,  0.5000],\n","        [-1.5000,  0.4000,  0.1000],\n","        [ 0.1000,  0.1000, -1.0000],\n","        [-1.2000,  0.5000, -0.8000]], dtype=torch.float64)\n","The raw scores matrix is:\n"," tensor([[-0.6171, -0.6427, -0.4438],\n","        [ 3.5357, -0.7126,  1.8614],\n","        [-4.7127, -0.1660, -2.3940],\n","        [ 0.2821,  1.4427,  0.3789],\n","        [-1.6298,  1.3386, -1.6126],\n","        [ 3.1418, -1.2601,  2.2101]], dtype=torch.float64)\n","The softmax-activated raw scores:\n","tensor([[0.3161, 0.3081, 0.3759],\n","        [0.8321, 0.0119, 0.1560],\n","        [0.0095, 0.8942, 0.0963],\n","        [0.1889, 0.6030, 0.2081],\n","        [0.0466, 0.9061, 0.0474],\n","        [0.7112, 0.0087, 0.2801]], dtype=torch.float64)\n","The average traning loss :\n","1.2303940464309857\n"]}]},{"cell_type":"code","source":["print(Y)# actual valuese\n","print(A) # softmax converted values\n","print(Y*A) # multiply them\n","sum = torch.sum(Y*A,dim = 1)\n","print(\"sum:\",sum)\n","log_loss = -torch.log(sum)\n","print(log_loss)\n","avg_loss = torch.mean(log_loss)\n","print(avg_loss)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k50qDs55I0Mz","executionInfo":{"status":"ok","timestamp":1754402415840,"user_tz":-330,"elapsed":85,"user":{"displayName":"Harshith M P","userId":"01234438332290187990"}},"outputId":"e307676e-40e7-4d11-dd9a-6400485867bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0., 1., 0.],\n","        [1., 0., 0.],\n","        [0., 1., 0.],\n","        [0., 0., 1.],\n","        [1., 0., 0.],\n","        [0., 0., 1.]], dtype=torch.float64)\n","tensor([[0.3161, 0.3081, 0.3759],\n","        [0.8321, 0.0119, 0.1560],\n","        [0.0095, 0.8942, 0.0963],\n","        [0.1889, 0.6030, 0.2081],\n","        [0.0466, 0.9061, 0.0474],\n","        [0.7112, 0.0087, 0.2801]], dtype=torch.float64)\n","tensor([[0.0000, 0.3081, 0.0000],\n","        [0.8321, 0.0000, 0.0000],\n","        [0.0000, 0.8942, 0.0000],\n","        [0.0000, 0.0000, 0.2081],\n","        [0.0466, 0.0000, 0.0000],\n","        [0.0000, 0.0000, 0.2801]], dtype=torch.float64)\n","sum: tensor([0.3081, 0.8321, 0.8942, 0.2081, 0.0466, 0.2801], dtype=torch.float64)\n","tensor([1.1774, 0.1838, 0.1118, 1.5697, 3.0671, 1.2726], dtype=torch.float64)\n","tensor(1.2304, dtype=torch.float64)\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"colab-windows","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.15"}},"nbformat":4,"nbformat_minor":0}